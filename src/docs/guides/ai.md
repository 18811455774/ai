# A Little History
We'll begin with a little history. If you are anxious to get to the practical bits, feel free to skip this section.

For starters, let's just assume artificial intelligence is about making computers smart in the way that we consider each other smart: that is, we can talk and undersatnd each other, we can take take sensory inputs and work out plans to navigate the world, we can manipulate objects and develop complex plans to achieve our goals, and so forth.

Researchers have been trying to endow machines with these human capabilities since antiquity. The Wikipedia article on the [history of artificial intelligence](https://en.wikipedia.org/wiki/History_of_artificial_intelligence) covers some of the early attempts. But most historians would date the beginning of AI as we know it today to the [Dartmouth Summer Research Project on Artificial Intelligence](https://en.wikipedia.org/wiki/Dartmouth_workshop) over the summer of 1956.

In the 60+ years since that kickoff, researchers have tried many different techniques to program computers to mimic human intelligence. To a first approximation, that six-decade history AI divides reasonably well into "Classical AI" from "Modern AI".

In Classical AI, researchers used logical rules to model intelligence. Building AI meant representing the world in a set of data structures (such as trees or lists or sets) and then using rules (such as *and*, *or*, *if-then-else*, and so on) to reason about that knowledge. For example, we could represent language as a set of words, and we could perform machine translation by translating those words from one language to another, and then reordering the words since we know that languages put their nouns and verbs and adjectives in different places. Or we could try to solve vision recognition problems by describing cats as "four legged animals with whiskers" and then decompose that into a set of sub problems (*find legs*, *find whiskers*) and those problems into more detailed problems ('find edges', *separate foreground and background*).

Researchers enjoyed many successes: so many in fact that Marvin Minsky famously said in 1967 that "[within a generation...the problem of creating 'artificial intellignece' will substantically be solved]"(https://en.wikipedia.org/wiki/History_of_artificial_intelligence#cite_note-61)

Unfortunately, efforts based on these approaches eventually failed as widely applicable solutions. They succeeded in niche domains or small problems, or within environments in which the parameters for operation had been highly constrained or painstakingly assembled over long periods of time. But they failed to generalize, either to reliably find all cats versus just some types of cats, or to other cases. Even if you built a fairly good cat detector, that didn't help you build a car detector. Because the niche solutions failed to genearlize, the research community grew so disillsioned that funding and startups would vanish for years at a time in a set of so-called "[AI winters](https://en.wikipedia.org/wiki/AI_winter)."

If Classical AI was about very smart researchers creating rules attempting to understand the world, Modern AI techniques focus on letting computers derive their own "rules" using lots and lots of data. Rather than explicilty telling a computer how to find a cat, we'll just show the computer lots of examples of cats, and see if the computer can construct a cat detector by figuring out what differentiates cats from dogs or muffins or couches or motorcycles.

The Modern AI approach is to get a data set, and then use a set of machine learning techinques with cool names like logistic regression, decision trees, Guassian Naive Bayes, random forest, k-nearest neighbors, or deep learning on that that data set. So the general approach is to we'd gather a bunch of pictures with cats and another set of pictures without cats, and feed enough of these pictures to the algorithms. Given enough data, these machine learning algorithms can do a very good job (in many cases, better than humans) of distinguishing cats from any picture. 

Researchers are excited about the Modern AI approach because it seems to work across many different domains; that is to say, modern AI technqiues such as deep learning seem to be generalizing to solve many different class of problems. For example, page through Jeff Dean's presentation on [Trends and Developments in Deep Learning Research](https://www.slideshare.net/AIFrontiers/jeff-dean-trends-and-developments-in-deep-learning-research) for examples of how Google uses this Modern AI approach in everything from photo recognition to Inbox's Smart Replies to better search to disease diagnosis.  

> Note: For more detailed discussion we recommend the first chapter of Russell & Norvig's _Artificial Intelligence, A Modern Approach, 3rd edition_ entitled "What is AI?"


